{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ee175e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cached data found in 'cached_test_data_thinking_correctness_losses_logits'. Generating data from scratch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:32<00:00,  1.55it/s]\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample 1 ---\n",
      "Subject: abstract_algebra\n",
      "Question: Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q.\n",
      "Choices:\n",
      "  A) 0\n",
      "  B) 4\n",
      "  C) 2\n",
      "  D) 6\n",
      "Correct Answer: B (4)\n",
      "Model's Answer: A (0)\n",
      "Result: ✗ INCORRECT\n",
      "Loss: 2.5464\n",
      "Model's Reasoning:\n",
      "<bos><bos>The following is a multiple choice question. Think through it very briefly, then output only a single token corresponding to the right answer (A, B, C, or D).\n",
      " Question: Find the degree for the given field extension Q(sqrt(2), sqrt(3), sqrt(18)) over Q.\n",
      "A) 0\n",
      "B) 4\n",
      "C) 2\n",
      "D) 6\n",
      "Let me think through this very briefly (you have 50 tokens to think):\n",
      "1. The degree of the extension is the degree of the minimal polynomial of the element.\n",
      "2. The minimal polynomial of sqrt(2) is x^2 - 2.\n",
      "3. The minimal polynomial of sqrt(3) is x\n",
      "\n",
      " I will answer with either: A, B, C, or D. Based on my brief reasoning above, the answer is:\n",
      "A)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:31<00:00,  1.60it/s]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample 2 ---\n",
      "Subject: abstract_algebra\n",
      "Question: Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the index of <p> in S_5.\n",
      "Choices:\n",
      "  A) 8\n",
      "  B) 2\n",
      "  C) 24\n",
      "  D) 120\n",
      "Correct Answer: C (24)\n",
      "Model's Answer: A (8)\n",
      "Result: ✗ INCORRECT\n",
      "Loss: 2.3323\n",
      "Model's Reasoning:\n",
      "<bos><bos>The following is a multiple choice question. Think through it very briefly, then output only a single token corresponding to the right answer (A, B, C, or D).\n",
      " Question: Let p = (1, 2, 5, 4)(2, 3) in S_5 . Find the index of <p> in S_5.\n",
      "A) 8\n",
      "B) 2\n",
      "C) 24\n",
      "D) 120\n",
      "Let me think through this very briefly (you have 50 tokens to think):\n",
      "1. p is a permutation of S_5.\n",
      "2. p is a product of disjoint cycles.\n",
      "3. p is a product of disjoint cycles of length 2.\n",
      "4. p is a product of disjoint cycles of length \n",
      "\n",
      " I will answer with either: A, B, C, or D. Based on my brief reasoning above, the answer is:\n",
      "A)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:29<00:00,  1.72it/s]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample 3 ---\n",
      "Subject: abstract_algebra\n",
      "Question: Find all zeros in the indicated finite field of the given polynomial with coefficients in that field. x^5 + 3x^3 + x^2 + 2x in Z_5\n",
      "Choices:\n",
      "  A) 0\n",
      "  B) 1\n",
      "  C) 0,1\n",
      "  D) 0,4\n",
      "Correct Answer: D (0,4)\n",
      "Model's Answer: A (0)\n",
      "Result: ✗ INCORRECT\n",
      "Loss: 0.5742\n",
      "Model's Reasoning:\n",
      "<bos><bos>The following is a multiple choice question. Think through it very briefly, then output only a single token corresponding to the right answer (A, B, C, or D).\n",
      " Question: Find all zeros in the indicated finite field of the given polynomial with coefficients in that field. x^5 + 3x^3 + x^2 + 2x in Z_5\n",
      "A) 0\n",
      "B) 1\n",
      "C) 0,1\n",
      "D) 0,4\n",
      "Let me think through this very briefly (you have 50 tokens to think):\n",
      "1. The polynomial is x^5 + 3x^3 + x^2 + 2x.\n",
      "2. The coefficients are in Z_5.\n",
      "3. The polynomial has 5 zeros.\n",
      "4. The polynomial has\n",
      "\n",
      " I will answer with either: A, B, C, or D. Based on my brief reasoning above, the answer is:\n",
      "A)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [00:26<00:02,  1.69it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 204\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# Init all variables and load SAEs for all layers\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# TEST_OUTPUT_DIR = \"cached_test_data_thinking_correctness_losses_logits\"\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m \n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# Build tree\u001b[39;00m\n\u001b[32m    203\u001b[39m MMLU_test_split = load_dataset(\u001b[33m\"\u001b[39m\u001b[33mcais/mmlu\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mall\u001b[39m\u001b[33m\"\u001b[39m, split=\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m test_feature_vectors, test_correctness_labels, test_losses, test_output_logits = \u001b[43mload_or_create_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_bidict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMMLU_test_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTEST_OUTPUT_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m X_test, X_stop_test, y_test, y_stop_test = train_test_split(\n\u001b[32m    206\u001b[39m     test_feature_vectors, \n\u001b[32m    207\u001b[39m     test_losses, \n\u001b[32m    208\u001b[39m     test_size=\u001b[32m0.1\u001b[39m,\n\u001b[32m    209\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m    210\u001b[39m )\n\u001b[32m    211\u001b[39m test_data = lgb.Dataset(X_test, label=y_test)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 181\u001b[39m, in \u001b[36mload_or_create_data\u001b[39m\u001b[34m(model, saes, feature_bidict, mmlu_dataset, output_dir)\u001b[39m\n\u001b[32m    179\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo cached data found in \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Generating data from scratch...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    180\u001b[39m     questions = get_all_mmlu_questions(mmlu_dataset)\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     feature_vectors, correctness_labels, losses, output_logits = \u001b[43mextract_features_and_correctness\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_bidict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m feature_vectors, correctness_labels, losses, output_logits\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 139\u001b[39m, in \u001b[36mextract_features_and_correctness\u001b[39m\u001b[34m(model, saes, questions, feature_bidict, output_dir)\u001b[39m\n\u001b[32m    137\u001b[39m all_output_logits = []\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, question \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(questions):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     feature_vector, is_correct, loss, output_logits = \u001b[43mprocess_question\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_bidict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m     all_feature_vectors.append(feature_vector)\n\u001b[32m    143\u001b[39m     all_correctness_labels.append(is_correct)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mprocess_question\u001b[39m\u001b[34m(model, saes, question, feature_bidict, sample_idx)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# Stage 1: Generate reasoning\u001b[39;00m\n\u001b[32m     61\u001b[39m     reasoning_prompt = question_text.replace(\u001b[33m\"\u001b[39m\u001b[33mAnswer: \u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mLet me think through this very briefly (you have 50 tokens to think):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     reasoning_tokens = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreasoning_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_bos\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# Stage 2: Generate final answer\u001b[39;00m\n\u001b[32m     69\u001b[39m     reasoning_text = model.to_string(reasoning_tokens[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/estimating_nns.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/estimating_nns.venv/lib/python3.11/site-packages/transformer_lens/HookedTransformer.py:2262\u001b[39m, in \u001b[36mHookedTransformer.generate\u001b[39m\u001b[34m(self, input, max_new_tokens, stop_at_eos, eos_token_id, do_sample, top_k, top_p, temperature, freq_penalty, use_past_kv_cache, prepend_bos, padding_side, return_type, verbose)\u001b[39m\n\u001b[32m   2259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_past_kv_cache:\n\u001b[32m   2260\u001b[39m     \u001b[38;5;66;03m# We just take the final tokens, as a [batch, 1] tensor\u001b[39;00m\n\u001b[32m   2261\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2262\u001b[39m         logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2263\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2264\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogits\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2265\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprepend_bos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepend_bos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2266\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2267\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2268\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstart_at_layer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_at_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2269\u001b[39m \u001b[43m            \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2270\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2271\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2272\u001b[39m         logits = \u001b[38;5;28mself\u001b[39m.forward(\n\u001b[32m   2273\u001b[39m             residual,\n\u001b[32m   2274\u001b[39m             return_type=\u001b[33m\"\u001b[39m\u001b[33mlogits\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2279\u001b[39m             shortformer_pos_embed=shortformer_pos_embed,\n\u001b[32m   2280\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/estimating_nns.venv/lib/python3.11/site-packages/transformer_lens/HookedTransformer.py:620\u001b[39m, in \u001b[36mHookedTransformer.forward\u001b[39m\u001b[34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[39m\n\u001b[32m    615\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    616\u001b[39m         shortformer_pos_embed = shortformer_pos_embed.to(\n\u001b[32m    617\u001b[39m             devices.get_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m.cfg)\n\u001b[32m    618\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m     residual = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[32m    623\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[32m    624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    630\u001b[39m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[32m    631\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/estimating_nns.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/estimating_nns.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/estimating_nns.venv/lib/python3.11/site-packages/transformer_lens/components/transformer_block.py:160\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[39m\n\u001b[32m    153\u001b[39m     key_input = attn_in\n\u001b[32m    154\u001b[39m     value_input = attn_in\n\u001b[32m    156\u001b[39m attn_out = (\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cfg.use_normalization_before_and_after:\n\u001b[32m    171\u001b[39m     \u001b[38;5;66;03m# If we use LayerNorm both before and after, then apply the second LN after the layer\u001b[39;00m\n\u001b[32m    172\u001b[39m     \u001b[38;5;66;03m# and before the hook. We do it before the hook so hook_attn_out captures \"that which\u001b[39;00m\n\u001b[32m    173\u001b[39m     \u001b[38;5;66;03m# is added to the residual stream\"\u001b[39;00m\n\u001b[32m    174\u001b[39m     attn_out = \u001b[38;5;28mself\u001b[39m.ln1_post(attn_out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/estimating_nns.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/estimating_nns.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/estimating_nns.venv/lib/python3.11/site-packages/transformer_lens/components/abstract_attention.py:210\u001b[39m, in \u001b[36mAbstractAttention.forward\u001b[39m\u001b[34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask, position_bias)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    183\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    184\u001b[39m     query_input: Union[\n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m     position_bias: Optional[Float[torch.Tensor, \u001b[33m\"\u001b[39m\u001b[33m1 head_index pos kv_pos\u001b[39m\u001b[33m\"\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    202\u001b[39m ) -> Float[torch.Tensor, \u001b[33m\"\u001b[39m\u001b[33mbatch pos d_model\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    203\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[33;03m    shortformer_pos_embed is only used if self.cfg.positional_embedding_type == \"shortformer\", else defaults to None and is irrelevant. See HookedTransformerConfig for more details\u001b[39;00m\n\u001b[32m    205\u001b[39m \u001b[33;03m    past_kv_cache_entry is an optional entry of past keys and values for this layer, only relevant if generating text. Defaults to None\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[33;03m    additive_attention_mask is an optional mask to add to the attention weights. Defaults to None.\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[33;03m    attention_mask is the attention mask for padded tokens. Defaults to None.\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m     q, k, v = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcalculate_qkv_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m past_kv_cache_entry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    213\u001b[39m         \u001b[38;5;66;03m# Appends the new keys and values to the cached values, and automatically updates the cache\u001b[39;00m\n\u001b[32m    214\u001b[39m         kv_cache_pos_offset = past_kv_cache_entry.past_keys.size(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/estimating_nns.venv/lib/python3.11/site-packages/transformer_lens/components/grouped_query_attention.py:139\u001b[39m, in \u001b[36mGroupedQueryAttention.calculate_qkv_matrices\u001b[39m\u001b[34m(self, query_input, key_input, value_input)\u001b[39m\n\u001b[32m    127\u001b[39m q = \u001b[38;5;28mself\u001b[39m.hook_q(\n\u001b[32m    128\u001b[39m     attn_fn(query_input, \u001b[38;5;28mself\u001b[39m.W_Q, \u001b[38;5;28mself\u001b[39m.b_Q)\n\u001b[32m    129\u001b[39m )  \u001b[38;5;66;03m# [batch, pos, head_index, d_head]\u001b[39;00m\n\u001b[32m    131\u001b[39m k = \u001b[38;5;28mself\u001b[39m.hook_k(\n\u001b[32m    132\u001b[39m     attn_fn(key_input, \u001b[38;5;28mself\u001b[39m.W_K, \u001b[38;5;28mself\u001b[39m.b_K)\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cfg.ungroup_grouped_query_attention\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m attn_fn(key_input, \u001b[38;5;28mself\u001b[39m._W_K, \u001b[38;5;28mself\u001b[39m._b_K)\n\u001b[32m    135\u001b[39m )  \u001b[38;5;66;03m# [batch, pos, head_index, d_head]\u001b[39;00m\n\u001b[32m    136\u001b[39m v = \u001b[38;5;28mself\u001b[39m.hook_v(\n\u001b[32m    137\u001b[39m     attn_fn(value_input, \u001b[38;5;28mself\u001b[39m.W_V, \u001b[38;5;28mself\u001b[39m.b_V)\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cfg.ungroup_grouped_query_attention\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mattn_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_W_V\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_b_V\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m )  \u001b[38;5;66;03m# [batch, pos, head_index, d_head]\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cfg.use_qk_norm:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.q_norm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/estimating_nns.venv/lib/python3.11/site-packages/transformer_lens/utilities/attention.py:24\u001b[39m, in \u001b[36msimple_attn_linear\u001b[39m\u001b[34m(input, w, b)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m.device != b.device:\n\u001b[32m     22\u001b[39m     b = b.to(\u001b[38;5;28minput\u001b[39m.device)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m w = \u001b[43meinops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhead_index d_model d_head -> (head_index d_head) d_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m b_ = einops.rearrange(b, \u001b[33m\"\u001b[39m\u001b[33mhead_index d_head -> (head_index d_head)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m F.linear(\u001b[38;5;28minput\u001b[39m, w, b_).reshape(\u001b[38;5;28minput\u001b[39m.shape[\u001b[32m0\u001b[39m], \u001b[38;5;28minput\u001b[39m.shape[\u001b[32m1\u001b[39m], b.shape[\u001b[32m0\u001b[39m], b.shape[\u001b[32m1\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/estimating_nns.venv/lib/python3.11/site-packages/einops/einops.py:600\u001b[39m, in \u001b[36mrearrange\u001b[39m\u001b[34m(tensor, pattern, **axes_lengths)\u001b[39m\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrearrange\u001b[39m(tensor: Union[Tensor, List[Tensor]], pattern: \u001b[38;5;28mstr\u001b[39m, **axes_lengths: Size) -> Tensor:\n\u001b[32m    546\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    547\u001b[39m \u001b[33;03m    einops.rearrange is a reader-friendly smart element reordering for multidimensional tensors.\u001b[39;00m\n\u001b[32m    548\u001b[39m \u001b[33;03m    This operation includes functionality of transpose (axes permutation), reshape (view), squeeze, unsqueeze,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    598\u001b[39m \n\u001b[32m    599\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrearrange\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43maxes_lengths\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/estimating_nns.venv/lib/python3.11/site-packages/einops/einops.py:532\u001b[39m, in \u001b[36mreduce\u001b[39m\u001b[34m(tensor, pattern, reduction, **axes_lengths)\u001b[39m\n\u001b[32m    530\u001b[39m     shape = backend.shape(tensor)\n\u001b[32m    531\u001b[39m     recipe = _prepare_transformation_recipe(pattern, reduction, axes_names=\u001b[38;5;28mtuple\u001b[39m(axes_lengths), ndim=\u001b[38;5;28mlen\u001b[39m(shape))\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_recipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_lengths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhashable_axes_lengths\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EinopsError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     message = \u001b[33m'\u001b[39m\u001b[33m Error while processing \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m-reduction pattern \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m.format(reduction, pattern)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/estimating_nns.venv/lib/python3.11/site-packages/einops/einops.py:251\u001b[39m, in \u001b[36m_apply_recipe\u001b[39m\u001b[34m(backend, recipe, tensor, reduction_type, axes_lengths)\u001b[39m\n\u001b[32m    249\u001b[39m     tensor = backend.add_axes(tensor, n_axes=n_axes_w_added, pos2len=added_axes)\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m final_shapes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     tensor = \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/estimating_nns.venv/lib/python3.11/site-packages/einops/_backends.py:93\u001b[39m, in \u001b[36mAbstractBackend.reshape\u001b[39m\u001b[34m(self, x, shape)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreshape\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, shape):\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sae_lens import SAE\n",
    "from transformer_lens import HookedTransformer\n",
    "from bidict import bidict\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_saes(device, total_layers=26):\n",
    "    \"\"\"Loads a series of Sparse Autoencoders (SAEs) for specified layers\"\"\"\n",
    "    saes = []\n",
    "    print(f\"Loading {total_layers} SAEs...\")\n",
    "    for layer in range(total_layers):\n",
    "        sae, _, _ = SAE.from_pretrained(\n",
    "            release=\"gemma-scope-2b-pt-res-canonical\",\n",
    "            sae_id=f\"layer_{layer}/width_16k/canonical\",\n",
    "            device=device\n",
    "        )\n",
    "        saes.append(sae)\n",
    "        print(f\"Layer {layer} loaded.\")\n",
    "    return saes\n",
    "\n",
    "def get_all_mmlu_questions(dataset):\n",
    "    \"\"\"Returns all questions from the MMLU dataset\"\"\"\n",
    "    all_questions = []\n",
    "    for i in range(len(dataset)):\n",
    "        data_point = dataset[i]\n",
    "        question = data_point['question']\n",
    "        choices = data_point['choices']\n",
    "        instruction = \"The following is a multiple choice question. Think through it very briefly, then output only a single token corresponding to the right answer (A, B, C, or D).\\n\"\n",
    "        formatted_question = instruction + f\" Question: {question}\\n\"\n",
    "        choice_labels = ['A', 'B', 'C', 'D']\n",
    "        for j, choice in enumerate(choices):\n",
    "            formatted_question += f\"{choice_labels[j]}) {choice}\\n\"\n",
    "        formatted_question += \"Answer: \"\n",
    "        all_questions.append({\n",
    "            'text': formatted_question,\n",
    "            'subject': data_point['subject'],\n",
    "            'answer': data_point['answer'],\n",
    "            'choices': data_point['choices'],\n",
    "            'raw_question': question\n",
    "        })\n",
    "    return all_questions\n",
    "        \n",
    "def process_question(model, saes, question, feature_bidict, sample_idx=None):\n",
    "    \"\"\"\n",
    "    Performs a forward pass, extracts features and loss for a single MMLU question\n",
    "    \"\"\"\n",
    "    question_text = question['text']\n",
    "    correct_answer_idx = question['answer']\n",
    "    choice_labels = ['A', 'B', 'C', 'D']\n",
    "    total_features = len(feature_bidict)\n",
    "    feature_vector = np.zeros(total_features, dtype=np.byte)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Stage 1: Generate reasoning\n",
    "        reasoning_prompt = question_text.replace(\"Answer: \", \"Let me think through this very briefly (you have 50 tokens to think):\\n\")\n",
    "        reasoning_tokens = model.generate(\n",
    "            model.to_tokens(reasoning_prompt, prepend_bos=True),\n",
    "            max_new_tokens=50,\n",
    "            do_sample=False\n",
    "        )\n",
    "\n",
    "        # Stage 2: Generate final answer\n",
    "        reasoning_text = model.to_string(reasoning_tokens[0])\n",
    "        final_prompt = reasoning_text + \"\\n\\n I will answer with either: A, B, C, or D. Based on my brief reasoning above, the answer is:\"\n",
    "        final_tokens = model.generate(\n",
    "            model.to_tokens(final_prompt, prepend_bos=True),\n",
    "            max_new_tokens=3,  # Just enough for the answer\n",
    "            do_sample=False\n",
    "        )\n",
    "        final_output = model.to_string(final_tokens[0])\n",
    "        # Run with cache on the FINAL tokens (not empty!)\n",
    "        logits, cache = model.run_with_cache(final_tokens)\n",
    "\n",
    "        choice_tokens = [model.to_tokens(label, prepend_bos=False)[0, 0].item() for label in ['A', 'B', 'C', 'D']]\n",
    "        answer_position = -1  # Default to last token\n",
    "        import re\n",
    "        reasoning_text = model.to_string(final_tokens[0])\n",
    "\n",
    "        # Just look for the last occurrence of A), B), C), or D)\n",
    "        last_answer = None\n",
    "        for choice in ['A)', 'B)', 'C)', 'D)']:\n",
    "            if choice in reasoning_text:\n",
    "                last_pos = reasoning_text.rfind(choice)  # Find LAST occurrence\n",
    "                if last_answer is None or last_pos > last_answer[1]:\n",
    "                    last_answer = (choice[0], last_pos)\n",
    "\n",
    "        if last_answer:\n",
    "            predicted_choice_idx = ['A', 'B', 'C', 'D'].index(last_answer[0])\n",
    "        else:\n",
    "            predicted_choice_idx = torch.argmax(last_token_logits).item()\n",
    "\n",
    "        last_token_logits = logits[0, answer_position, :]\n",
    "\n",
    "        choice_token_ids = [model.to_tokens(label, prepend_bos=False)[0, 0].item() for label in choice_labels]\n",
    "        choice_logits = last_token_logits[choice_token_ids]\n",
    "        output_logits = choice_logits.cpu().numpy()\n",
    "        loss = F.cross_entropy(choice_logits.unsqueeze(0), torch.tensor([correct_answer_idx]).to(model.cfg.device)).item()\n",
    "        #predicted_choice_idx = torch.argmax(choice_logits).item()\n",
    "        is_correct = predicted_choice_idx == correct_answer_idx\n",
    "\n",
    "        print(f\"\\n--- Sample {sample_idx} ---\")\n",
    "        print(f\"Subject: {question['subject']}\")\n",
    "        print(f\"Question: {question['raw_question']}\")\n",
    "        print(\"Choices:\")\n",
    "        for i, choice in enumerate(question['choices']):\n",
    "            print(f\"  {choice_labels[i]}) {choice}\")\n",
    "        print(f\"Correct Answer: {choice_labels[correct_answer_idx]} ({question['choices'][correct_answer_idx]})\")\n",
    "        print(f\"Model's Answer: {choice_labels[predicted_choice_idx]} ({question['choices'][predicted_choice_idx]})\")\n",
    "        print(f\"Result: {'✓ CORRECT' if is_correct else '✗ INCORRECT'}\")\n",
    "        print(f\"Loss: {loss:.4f}\")\n",
    "        print(f\"Model's Reasoning:\\n{final_output}\")\n",
    "\n",
    "        for layer_idx, sae in enumerate(saes):\n",
    "            final_token_activations = cache[sae.cfg.hook_name][0, -1, :].unsqueeze(0)\n",
    "            feature_acts = sae.encode(final_token_activations)\n",
    "            active_indices = torch.where(feature_acts > 0)[1].cpu().tolist()\n",
    "            for feature_idx in active_indices:\n",
    "                global_feature_idx = feature_bidict.get((layer_idx, feature_idx))\n",
    "                if global_feature_idx is not None:\n",
    "                    feature_vector[global_feature_idx] = 1\n",
    "\n",
    "    return feature_vector, is_correct, loss, output_logits\n",
    "        \n",
    "def extract_features_and_correctness(model, saes, questions, feature_bidict, output_dir=None):\n",
    "    \"\"\"\n",
    "    Processes questions to get features and correctness, with an option to save data\n",
    "    \"\"\"\n",
    "    all_feature_vectors = []\n",
    "    all_correctness_labels = []\n",
    "    all_losses = []\n",
    "    all_output_logits = []\n",
    "    for i, question in enumerate(questions):\n",
    "        feature_vector, is_correct, loss, output_logits = process_question(\n",
    "            model, saes, question, feature_bidict, sample_idx=i+1\n",
    "        )\n",
    "        all_feature_vectors.append(feature_vector)\n",
    "        all_correctness_labels.append(is_correct)\n",
    "        all_losses.append(loss)\n",
    "        all_output_logits.append(output_logits)\n",
    "\n",
    "    if output_dir:\n",
    "        features_np = np.array(all_feature_vectors, dtype=np.byte)\n",
    "        correctness_np = np.array(all_correctness_labels)\n",
    "        losses_np = np.array(all_losses)\n",
    "        output_logits_np =  np.array(all_output_logits)\n",
    "        feature_path = os.path.join(output_dir, f\"features.npy\")\n",
    "        correctness_path = os.path.join(output_dir, f\"correctness.npy\")\n",
    "        loss_path = os.path.join(output_dir, f\"losses.npy\")\n",
    "        output_logits_path = os.path.join(output_dir, f\"output_logits.npy\")\n",
    "        np.save(feature_path, features_np)\n",
    "        np.save(correctness_path, correctness_np)\n",
    "        np.save(loss_path, losses_np)\n",
    "        np.save(output_logits_path, output_logits_np)\n",
    "\n",
    "    return np.array(all_feature_vectors, dtype=np.byte), np.array(all_correctness_labels), np.array(all_losses), np.array(all_output_logits)\n",
    "\n",
    "def load_or_create_data(model, saes, feature_bidict, mmlu_dataset, output_dir):\n",
    "    feature_path = os.path.join(output_dir, \"features.npy\")\n",
    "    correctness_path = os.path.join(output_dir, \"correctness.npy\")\n",
    "    loss_path = os.path.join(output_dir, \"losses.npy\")\n",
    "    output_logits_path = os.path.join(output_dir, \"output_logits.npy\")\n",
    "    if os.path.exists(feature_path) and os.path.exists(correctness_path) and os.path.exists(loss_path): #and os.path.exists(output_logits_path):\n",
    "        print(f\"Found cached data. Loading from '{output_dir}'...\")\n",
    "        feature_vectors = np.load(feature_path)\n",
    "        correctness_labels = np.load(correctness_path)\n",
    "        losses = np.load(loss_path)\n",
    "        try: \n",
    "            output_logits = np.load(output_logits_path)\n",
    "        except:\n",
    "            print(\"output_logits set to None\")\n",
    "            output_logits = None\n",
    "    else:\n",
    "        print(f\"No cached data found in '{output_dir}'. Generating data from scratch...\")\n",
    "        questions = get_all_mmlu_questions(mmlu_dataset)\n",
    "        feature_vectors, correctness_labels, losses, output_logits = extract_features_and_correctness(\n",
    "            model, saes, questions, feature_bidict,\n",
    "            output_dir=output_dir)\n",
    "    return feature_vectors, correctness_labels, losses, output_logits\n",
    "\n",
    "\n",
    "# Init all variables and load SAEs for all layers\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# TEST_OUTPUT_DIR = \"cached_test_data_thinking_correctness_losses_logits\"\n",
    "# os.makedirs(TEST_OUTPUT_DIR, exist_ok=True)\n",
    "# model = HookedTransformer.from_pretrained(\"gemma-2-2b\", device=device)\n",
    "# saes = get_saes(device, total_layers=26)\n",
    "# feature_bidict = bidict()\n",
    "# global_idx = 0\n",
    "# for layer_idx, sae in enumerate(saes):\n",
    "#     for feature_idx in range(sae.cfg.d_sae):\n",
    "#         feature_bidict[(layer_idx, feature_idx)] = global_idx\n",
    "#         global_idx += 1\n",
    "# total_features = len(feature_bidict)\n",
    "# print(f\"Created mapping for {total_features} features across {len(saes)} layers\")\n",
    "\n",
    "# Build tree\n",
    "MMLU_test_split = load_dataset(\"cais/mmlu\", \"all\", split='test')\n",
    "test_feature_vectors, test_correctness_labels, test_losses, test_output_logits = load_or_create_data(model, saes, feature_bidict, MMLU_test_split, TEST_OUTPUT_DIR)\n",
    "X_test, X_stop_test, y_test, y_stop_test = train_test_split(\n",
    "    test_feature_vectors, \n",
    "    test_losses, \n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "test_data = lgb.Dataset(X_test, label=y_test)\n",
    "stop_test_data = lgb.Dataset(X_stop_test, label=y_stop_test, reference=test_data)\n",
    "print(f\"\\nExtracted {len(test_feature_vectors)} samples for tree construction. Building NAP tree...\")\n",
    "start_time = time.time()\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'rmse',\n",
    "    'max_depth': -1,\n",
    "    'num_leaves': 2048,\n",
    "    'min_data_in_leaf': 3,\n",
    "    'min_sum_hessian_in_leaf': 1e-4,\n",
    "    'feature_fraction': 1.0,\n",
    "    'feature_fraction_bynode': 1.0,\n",
    "    'bagging_fraction': 1.0,\n",
    "    'learning_rate': 0.01,\n",
    "    'lambda_l1': 0.05,\n",
    "    'lambda_l2': 0.05,\n",
    "    'num_threads': -1,\n",
    "    'force_row_wise': True,\n",
    "    'verbosity': 1,\n",
    "    'seed': 42,\n",
    "    'deterministic': True\n",
    "}\n",
    "model_lgb = lgb.train(\n",
    "    params, \n",
    "    test_data, \n",
    "    num_boost_round=2000,\n",
    "    valid_sets=[stop_test_data],\n",
    "    valid_names=['stop_test_data'],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=100),\n",
    "        lgb.log_evaluation(period=200)\n",
    "    ]\n",
    ")\n",
    "print(f\"LightGBM model built in {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c777968",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_OUTPUT_DIR = \"cached_validation_data_thinking_correctness_losses_logits\"\n",
    "os.makedirs(VALIDATION_OUTPUT_DIR, exist_ok=True)\n",
    "MMLU_validation_split = load_dataset(\"cais/mmlu\", \"all\", split='validation')\n",
    "validation_feature_vectors, validation_correctness_labels, validation_losses, output_logits = load_or_create_data(model, saes, feature_bidict, MMLU_validation_split, VALIDATION_OUTPUT_DIR)\n",
    "validation_loss_predictions = model_lgb.predict(validation_feature_vectors)\n",
    "low_loss_threshold = 0.651\n",
    "confident_mask = validation_loss_predictions < low_loss_threshold\n",
    "confident_correctness_labels = validation_correctness_labels[confident_mask]\n",
    "confident_accuracy = np.mean(confident_correctness_labels)\n",
    "\n",
    "print(f\"Coverage of confident predictions: {np.mean(confident_mask):.3f} ({np.sum(confident_mask)}/{len(validation_feature_vectors)} validation samples)\")\n",
    "print(f\"Accuracy on confident predictions: {np.mean(confident_correctness_labels):.4f}\")\n",
    "print(f\"Model's true validation accuracy: {np.sum(validation_correctness_labels) / len(validation_correctness_labels):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "estimating_nns.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
