{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fb87c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "10.788929 M parameters\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 208\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[32m    205\u001b[39m \n\u001b[32m    206\u001b[39m     \u001b[38;5;66;03m# every once in a while evaluate the loss on train and val sets\u001b[39;00m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m % eval_interval == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28miter\u001b[39m == max_iters - \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m         losses = \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28miter\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, val loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    211\u001b[39m     \u001b[38;5;66;03m# sample a batch of data\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mestimate_loss\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(eval_iters):\n\u001b[32m     55\u001b[39m     X, Y = get_batch(split)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     logits, loss = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     losses[k] = loss.item()\n\u001b[32m     58\u001b[39m out[split] = losses.mean()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 165\u001b[39m, in \u001b[36mGPTLanguageModel.forward\u001b[39m\u001b[34m(self, idx, targets)\u001b[39m\n\u001b[32m    163\u001b[39m pos_emb = \u001b[38;5;28mself\u001b[39m.position_embedding_table(torch.arange(T, device=device)) \u001b[38;5;66;03m# (T,C)\u001b[39;00m\n\u001b[32m    164\u001b[39m x = tok_emb + pos_emb \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[32m    166\u001b[39m x = \u001b[38;5;28mself\u001b[39m.ln_f(x) \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[32m    167\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.lm_head(x) \u001b[38;5;66;03m# (B,T,vocab_size)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 132\u001b[39m, in \u001b[36mBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     x = x + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msa\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m     x = x + \u001b[38;5;28mself\u001b[39m.ffwd(\u001b[38;5;28mself\u001b[39m.ln2(x))\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 100\u001b[39m, in \u001b[36mMultiHeadAttention.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     out = torch.cat(\u001b[43m[\u001b[49m\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheads\u001b[49m\u001b[43m]\u001b[49m, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    101\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.dropout(\u001b[38;5;28mself\u001b[39m.proj(out))\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 100\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     out = torch.cat([\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.heads], dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    101\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.dropout(\u001b[38;5;28mself\u001b[39m.proj(out))\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 78\u001b[39m, in \u001b[36mHead.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     75\u001b[39m     \u001b[38;5;66;03m# input of size (batch, time-step, channels)\u001b[39;00m\n\u001b[32m     76\u001b[39m     \u001b[38;5;66;03m# output of size (batch, time-step, head size)\u001b[39;00m\n\u001b[32m     77\u001b[39m     B,T,C = x.shape\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     k = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# (B,T,hs)\u001b[39;00m\n\u001b[32m     79\u001b[39m     q = \u001b[38;5;28mself\u001b[39m.query(x) \u001b[38;5;66;03m# (B,T,hs)\u001b[39;00m\n\u001b[32m     80\u001b[39m     \u001b[38;5;66;03m# compute attention scores (\"affinities\")\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Estimating_NNs/.venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "# hyperparameters\n",
    "batch_size = 64 # how many independent sequences will we process in parallel?\n",
    "block_size = 256 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "eval_iters = 200\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input of size (batch, time-step, channels)\n",
    "        # output of size (batch, time-step, head size)\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,hs)\n",
    "        q = self.query(x) # (B,T,hs)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,hs)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class GPTLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        # better init, not covered in the original GPT video, but important, will cover in followup video\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = GPTLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "#open('more.txt', 'w').write(decode(m.generate(context, max_new_tokens=10000)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "862b9059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANUS:\n",
      "Yo'er blent bid thee in the treaches on what;\n",
      "Taking thus honour in thy face.\n",
      "Cature it, loves betimes; when so oft thine\n",
      "I cannot stince be in the veigh?\n",
      "\n",
      "First Water:\n",
      "The caulth in recense bearship the strange out\n",
      "issing of his eye on the spirit\n",
      "inforce itseluy, were puspecion; if for the posed\n",
      "of presence be allowant and unmost absoluto; our\n",
      "he vences are secred the father usure,\n",
      "it owads so, it is a momonth any countinues the plot\n",
      "damned. With thereof it is ensoil'd\n",
      "our huning Virtues:\n"
     ]
    }
   ],
   "source": [
    "model = GPTLanguageModel()\n",
    "model.load_state_dict(torch.load('model.pth', map_location='cpu'))\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(model.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b52d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step 1/1000\n",
      "  Full dimension: 65, Active dimensions: 65\n",
      "  Added regularization: 5.28e-07\n",
      "  Successfully created 65-dimensional Gaussian\n",
      "  Covariance eigenvalues: 1.00e-06 to 5.44e-05\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'log_prob'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 361\u001b[39m\n\u001b[32m    358\u001b[39m estimated_output_distribution = estimated_layer_gaussian\n\u001b[32m    359\u001b[39m true_outputs, generated_tokens = find_true_outputs(model, input_points, device)\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m surprise_estimate = \u001b[43msurprise_of_estimate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimated_output_distribution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    362\u001b[39m surprise_metric1 = surprise_of_argument_metric1(layer_masks, covariance_matrices)\n\u001b[32m    363\u001b[39m \u001b[38;5;28mprint\u001b[39m(surprise_estimate, surprise_metric1)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 247\u001b[39m, in \u001b[36msurprise_of_estimate\u001b[39m\u001b[34m(true_samples, estimated_output_distribution)\u001b[39m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(sample.shape[\u001b[32m0\u001b[39m]):\n\u001b[32m    246\u001b[39m     single_sample = sample[i]  \u001b[38;5;66;03m# Single vector of vocab_size\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     log_prob = \u001b[43mestimated_output_distribution\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_prob\u001b[49m(single_sample)\n\u001b[32m    248\u001b[39m     total_log_prob += log_prob\n\u001b[32m    249\u001b[39m     sample_count += \u001b[32m1\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'log_prob'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from torch.distributions import MultivariateNormal\n",
    "'''\n",
    "Collect training data activations: Forward pass normal examples through your neural network and record activations at each layer\n",
    "Fit Gaussian distributions per layer: For each layer i, calculate empirical mean μᵢ and covariance matrix Σᵢ from the training activations\n",
    "Create sparse argument masks: Start with diagonal covariance matrices (independence assumption) - boolean masks that select which covariance terms to track\n",
    "For new inputs: Forward pass through network to get activations x*ᵢ at each layer\n",
    "Compute anomaly score: Sum the negative log probabilities across layers: Σᵢ (-log Pᵢ(x*ᵢ)) where Pᵢ = N(μᵢ, Σᵢ)\n",
    "Set threshold: Use validation data to determine anomaly threshold (e.g., 95th percentile of normal examples)\n",
    "Flag anomalies: Inputs scoring above threshold are anomalies\n",
    "'''\n",
    "\n",
    "def calculate_layer_statistics(activations):\n",
    "    stacked_activations = []\n",
    "    for activation in activations:\n",
    "        # Ensure consistent dtype\n",
    "        activation = activation.float()\n",
    "        # Flatten batch and time dimensions: (B, T, n_embd) -> (B*T, n_embd)\n",
    "        flattened = activation.view(-1, activation.shape[-1])\n",
    "        stacked_activations.append(flattened)\n",
    "    all_samples = torch.cat(stacked_activations, dim=0)\n",
    "    # empirical mean μ̂ = (1/N) Σ(i=1 to N) x_i\n",
    "    empirical_mean = torch.mean(all_samples, dim=0)\n",
    "    # Center the data\n",
    "    centered_samples = all_samples - empirical_mean.unsqueeze(0)\n",
    "    # covariance matrix Σ̂ = (1/N) Σ(i=1 to N) (x_i - μ̂)(x_i - μ̂)^T\n",
    "    covariance_matrix = torch.mm(centered_samples.t(), centered_samples) / (all_samples.shape[0] - 1)\n",
    "    \n",
    "    return empirical_mean, covariance_matrix\n",
    "\n",
    "def create_sparse_argument_masks(covariance_matrix):\n",
    "    dim = covariance_matrix.shape[0]\n",
    "    # Create diagonal mask (to assume independence between activations)\n",
    "    mask = torch.eye(dim, dtype=torch.bool, device=covariance_matrix.device)\n",
    "    return mask\n",
    "\n",
    "def make_layer_mask(best_layer_mask, covariance_matrix, lr=0.05):\n",
    "    if best_layer_mask is None:\n",
    "        return create_sparse_argument_masks(covariance_matrix)\n",
    "    \n",
    "    new_mask = best_layer_mask.clone()\n",
    "    dim = best_layer_mask.shape[0]\n",
    "    \n",
    "    def is_positive_definite(matrix):\n",
    "        try:\n",
    "            torch.linalg.cholesky(matrix)\n",
    "            return True\n",
    "        except torch.linalg.LinAlgError:\n",
    "            return False\n",
    "    \n",
    "    # Go through upper triangular positions\n",
    "    positions = [(i, j) for i in range(dim) for j in range(i, dim)]\n",
    "    random.shuffle(positions)\n",
    "    for i, j in positions:\n",
    "        # Skip with probability (1 - lr)\n",
    "        if random.random() >= lr:\n",
    "            continue\n",
    "        # Try flipping the bit\n",
    "        original_val = new_mask[i, j].item()\n",
    "        new_mask[i, j] = not original_val\n",
    "        # Maintain symmetry\n",
    "        if i != j:\n",
    "            new_mask[j, i] = new_mask[i, j]\n",
    "        # Test if the masked matrix is still positive definite\n",
    "        masked_matrix = covariance_matrix * new_mask.float()\n",
    "        if not is_positive_definite(masked_matrix):\n",
    "            new_mask[i, j] = original_val\n",
    "            if i != j:\n",
    "                new_mask[j, i] = original_val\n",
    "    \n",
    "    return new_mask\n",
    "\n",
    "def get_activation(input_points, layer, model, device='cpu'):\n",
    "    layer_activations = []\n",
    "    block_idx = layer\n",
    "    for sampled_activation in input_points:\n",
    "        sampled_activation = sampled_activation.to(device).float()  # Ensure float type\n",
    "        with torch.no_grad():\n",
    "            x = sampled_activation\n",
    "            # Pass through the specific transformer block\n",
    "            block = model.blocks[block_idx]\n",
    "            # Pre-attention layer norm\n",
    "            ln1_out = block.ln1(x)\n",
    "            # Self-attention\n",
    "            sa_out = block.sa(ln1_out)\n",
    "            # Residual connection after attention\n",
    "            x = x + sa_out\n",
    "            # Pre-feedforward layer norm\n",
    "            ln2_out = block.ln2(x)\n",
    "            # Feedforward\n",
    "            ffwd_out = block.ffwd(ln2_out)\n",
    "            # Residual connection after feedforward\n",
    "            x = x + ffwd_out\n",
    "            layer_activations.append(x)\n",
    "    return layer_activations\n",
    "\n",
    "def propagate_distribution(input_points, layer, model):\n",
    "    layer_activations = get_activation(input_points, layer, model)\n",
    "    layer_empirical_mean, layer_covariance_matrix = calculate_layer_statistics(layer_activations)\n",
    "    return layer_empirical_mean, layer_covariance_matrix, layer_activations\n",
    "\n",
    "def create_gaussian_distribution(empirical_mean, covariance_matrix, layer_mask):\n",
    "    # Only keep covariance terms where mask is True, set others to 0\n",
    "    masked_cov = covariance_matrix * layer_mask.float()\n",
    "    masked_cov = 1e-6 * torch.eye(masked_cov.shape[0])\n",
    "    distribution = MultivariateNormal(loc=empirical_mean, covariance_matrix=masked_cov)\n",
    "    return distribution\n",
    "\n",
    "def sample_next_layer_inputs(estimated_layer_gaussian, original_activations, num_activations):\n",
    "    # Get the original shape from one of the activations\n",
    "    sample_activation = original_activations[0]\n",
    "    batch_size, seq_len, feature_dim = sample_activation.shape\n",
    "    \n",
    "    # Sample from the distribution\n",
    "    # We need (num_activations * batch_size * seq_len) samples\n",
    "    total_samples_needed = num_activations * batch_size * seq_len\n",
    "    sampled_flat = estimated_layer_gaussian.sample((total_samples_needed,))\n",
    "    \n",
    "    # Reshape to match the expected format: (num_activations, batch_size, seq_len, feature_dim)\n",
    "    sampled_activations = sampled_flat.view(num_activations, batch_size, seq_len, feature_dim)\n",
    "    \n",
    "    # Convert back to list format expected by the rest of the code\n",
    "    current_layer_inputs = [sampled_activations[i] for i in range(num_activations)]\n",
    "    \n",
    "    return current_layer_inputs\n",
    "\n",
    "def find_true_outputs(model, input_points, device='cpu'):\n",
    "    true_outputs = []\n",
    "    generated_tokens = []  # Store the actual tokens generated\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for input_point in input_points:\n",
    "            input_point = input_point.to(device).long()  # Ensure long type for embeddings\n",
    "            B, T = input_point.shape\n",
    "            \n",
    "            # Token embeddings\n",
    "            tok_emb = model.token_embedding_table(input_point).float()  # (B, T, n_embd)\n",
    "            \n",
    "            # Position embeddings\n",
    "            pos_emb = model.position_embedding_table(torch.arange(T, device=device)).float()  # (T, n_embd)\n",
    "            \n",
    "            # Combined embeddings\n",
    "            x = tok_emb + pos_emb  # (B, T, n_embd)\n",
    "            \n",
    "            # Pass through all transformer blocks\n",
    "            for block in model.blocks:\n",
    "                # Pre-attention layer norm\n",
    "                ln1_out = block.ln1(x)\n",
    "                # Self-attention\n",
    "                sa_out = block.sa(ln1_out)\n",
    "                # Residual connection after attention\n",
    "                x = x + sa_out\n",
    "                # Pre-feedforward layer norm\n",
    "                ln2_out = block.ln2(x)\n",
    "                # Feedforward\n",
    "                ffwd_out = block.ffwd(ln2_out)\n",
    "                # Residual connection after feedforward\n",
    "                x = x + ffwd_out\n",
    "            \n",
    "            # Final layer norm\n",
    "            ln_f_out = model.ln_f(x)  # (B, T, n_embd)\n",
    "            \n",
    "            # Language model head (logits)\n",
    "            logits = model.lm_head(ln_f_out)  # (B, T, vocab_size)\n",
    "            \n",
    "            # Convert logits to actual tokens\n",
    "            # Take the last token prediction for each sequence\n",
    "            last_token_logits = logits[:, -1, :]  # (B, vocab_size)\n",
    "            predicted_token_ids = torch.argmax(last_token_logits, dim=-1)  # (B,)\n",
    "            \n",
    "            # Decode to actual text\n",
    "            for batch_idx in range(B):\n",
    "                token_id = predicted_token_ids[batch_idx].item()\n",
    "                predicted_char = itos[token_id]  # Convert to character using your decoder\n",
    "                generated_tokens.append(predicted_char)\n",
    "            \n",
    "            # Flatten the logits to match expected input format for calculate_layer_statistics\n",
    "            # This converts (B, T, vocab_size) -> (B*T, vocab_size)\n",
    "            flattened_logits = logits.view(-1, logits.shape[-1])\n",
    "            true_outputs.append(flattened_logits)\n",
    "            \n",
    "    return true_outputs, generated_tokens\n",
    "    \n",
    "def surprise_of_estimate(true_samples, estimated_output_distribution):\n",
    "    total_log_prob = 0.0\n",
    "    sample_count = 0\n",
    "    \n",
    "    for sample in true_samples:\n",
    "        # Process each sample individually\n",
    "        for i in range(sample.shape[0]):\n",
    "            single_sample = sample[i]  # Single vector of vocab_size\n",
    "            log_prob = estimated_output_distribution.log_prob(single_sample)\n",
    "            total_log_prob += log_prob\n",
    "            sample_count += 1\n",
    "    \n",
    "    return -(total_log_prob / sample_count).item()\n",
    "\n",
    "def surprise_of_argument_metric1(layer_masks, covariance_matrices):\n",
    "    total_surprise = 0.0\n",
    "    for i, (mask, cov_matrix) in enumerate(zip(layer_masks, covariance_matrices)):\n",
    "        # Count number of True elements in the mask (|πᵢ|)\n",
    "        num_tracked_elements = torch.sum(mask.float()).item()\n",
    "        # Dimension of the space (dim(Xᵢ))\n",
    "        dimension = cov_matrix.shape[0]\n",
    "        # Surprise is the excess over diagonal elements\n",
    "        # We subtract dimension because diagonal elements don't add surprise\n",
    "        # (they represent the base independence assumption)\n",
    "        layer_surprise = num_tracked_elements - dimension\n",
    "        total_surprise += max(0, layer_surprise)  # Only count positive deviations\n",
    "    return total_surprise\n",
    "\n",
    "def surprise_of_argument_metric2(layer_masks, estimated_gaussians, naive_gaussians):\n",
    "    total_surprise = 0.0\n",
    "    for i, (estimated_dist, naive_dist) in enumerate(zip(estimated_gaussians, naive_gaussians)):\n",
    "        # Compute KL divergence: KL(P_i^π || Q_i)\n",
    "        kl_div = torch.distributions.kl_divergence(estimated_dist, naive_dist)\n",
    "        if torch.isfinite(kl_div):\n",
    "            total_surprise += kl_div.item()\n",
    "        else:\n",
    "            # If KL divergence is infinite/NaN, add a large penalty\n",
    "            total_surprise += 1000.0\n",
    "    return total_surprise\n",
    "\n",
    "def score_input(activation, best_heuristic_argument):\n",
    "    #Anomaly Score = Σᵢ (-log Pᵢᵖ(x*ᵢ))\n",
    "    score = 0\n",
    "    return score\n",
    "\n",
    "# Main training loop\n",
    "model = GPTLanguageModel()\n",
    "model.load_state_dict(torch.load('model.pth', map_location='cpu'))\n",
    "device = 'cpu'\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "num_activations = 60\n",
    "best_masks = [None] * 8  # Increased to 8 to match n_layer + 1\n",
    "min_surprise = 100000\n",
    "num_train_steps = 1000\n",
    "num_layers = 8\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(num_train_steps):\n",
    "        print(f\"Training step {i+1}/{num_train_steps}\")\n",
    "        \n",
    "        covariance_matrices = []\n",
    "        empirical_means = []\n",
    "        estimated_gaussians = []\n",
    "        layer_masks = []\n",
    "        input_points = []\n",
    "        \n",
    "        # Generate input points\n",
    "        for iter in range(num_activations):\n",
    "            xb, yb = get_batch('train')\n",
    "            input_point = xb.to(device)\n",
    "            input_points.append(input_point)\n",
    "        \n",
    "        current_layer_inputs = []\n",
    "        for input_point in input_points:\n",
    "            input_point = input_point.to(device).long()  # Ensure input is long type for embeddings\n",
    "            with torch.no_grad():\n",
    "                B, T = input_point.shape\n",
    "                # Token embeddings\n",
    "                tok_emb = model.token_embedding_table(input_point).float()  # (B, T, n_embd)\n",
    "                # Position embeddings\n",
    "                pos_emb = model.position_embedding_table(torch.arange(T, device=device)).float()  # (T, n_embd)\n",
    "                # Combined embeddings\n",
    "                x = tok_emb + pos_emb  # (B, T, n_embd)\n",
    "                current_layer_inputs.append(x)\n",
    "        \n",
    "        # Process each layer\n",
    "        for layer in range(n_layer):\n",
    "            empirical_mean, covariance_matrix, layer_activations = propagate_distribution(current_layer_inputs, layer, model)\n",
    "            empirical_means.append(empirical_mean)\n",
    "            covariance_matrices.append(covariance_matrix)\n",
    "\n",
    "            layer_mask = make_layer_mask(best_masks[layer], covariance_matrix, lr=0.1)\n",
    "            layer_masks.append(layer_mask)\n",
    "            \n",
    "            estimated_layer_gaussian = create_gaussian_distribution(empirical_mean, covariance_matrix, layer_mask)\n",
    "            estimated_gaussians.append(estimated_layer_gaussian)\n",
    "            current_layer_inputs = sample_next_layer_inputs(\n",
    "                estimated_layer_gaussian, layer_activations, num_activations\n",
    "            )\n",
    "                # sampled_activations = estimated_layer_gaussian.sample((num_activations,))  # Shape: (num_activations, feature_dim)\n",
    "                # # Reshape to match expected input format (B, T, n_embd)\n",
    "                # current_layer_inputs = [sampled_activations[i].unsqueeze(0).unsqueeze(0) for i in range(num_activations)]\n",
    "\n",
    "        # Calculate surprise metrics\n",
    "        layer_activations = []\n",
    "        for sampled_activation in current_layer_inputs:\n",
    "            sampled_activation = sampled_activation.to(device).float()  # Ensure float type\n",
    "            with torch.no_grad():\n",
    "                # Final layer norm\n",
    "                ln_f_out = model.ln_f(sampled_activation)\n",
    "                # Language model head (logits)\n",
    "                logits = model.lm_head(ln_f_out)\n",
    "                layer_activations.append(logits)\n",
    "        empirical_mean, covariance_matrix = calculate_layer_statistics(layer_activations)\n",
    "        dim = covariance_matrix.shape[0]\n",
    "        layer_mask = torch.ones(dim, dim, dtype=torch.bool, device=covariance_matrix.device)\n",
    "        estimated_layer_gaussian = create_efficient_gaussian_distribution(empirical_mean, covariance_matrix, layer_mask)\n",
    "\n",
    "        estimated_output_distribution = estimated_layer_gaussian\n",
    "        true_outputs, generated_tokens = find_true_outputs(model, input_points, device)\n",
    "        \n",
    "        surprise_estimate = surprise_of_estimate(true_outputs, estimated_output_distribution)\n",
    "        surprise_metric1 = surprise_of_argument_metric1(layer_masks, covariance_matrices)\n",
    "        print(surprise_estimate, surprise_metric1)\n",
    "        print(generated_tokens)\n",
    "        total_surprise = surprise_estimate + surprise_metric1\n",
    "        print(f\"Current total surprise: {total_surprise}\")\n",
    "        if total_surprise < min_surprise:\n",
    "            min_surprise = total_surprise\n",
    "            best_masks = layer_masks.copy()\n",
    "            print(f\"New best surprise: {min_surprise}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Deploy on one example\n",
    "# max_allowed_anomaly_score = 0\n",
    "# for datapoint in dataset:\n",
    "#     activation = record_activation(model, input)\n",
    "#     anomaly_score = score_input(activation, best_heuristic_argument, covariance_matrices)\n",
    "#     if max_allowed_anomaly_score < anomaly_score:\n",
    "#         max_allowed_anomaly_score = anomaly_score\n",
    "# input = 5\n",
    "# activation = record_activation(model, input)\n",
    "# anomaly_score = score_input(activation, best_heuristic_argument, covariance_matrices)\n",
    "# if anomaly_score > max_allowed_anomaly_score:\n",
    "#     print(\"ANOMALY\")\n",
    "# else:\n",
    "#     print(\"ALL GOOD\")\n",
    "\n",
    "\n",
    "# 2. Estimate loss over one distribution \n",
    "\n",
    "\n",
    "# 3. Perform Low Probability Estimation over one distribution \n",
    "\n",
    "\n",
    "# 4. Fit only the last layer as a baseline\n",
    "\n",
    "#205.51065063476562"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dc9def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING ENHANCED TRAINING WITH MONITORING\n",
      "============================================================\n",
      "\n",
      "==================== Training Step 1/1000 ====================\n",
      "\n",
      "--- Generating 60 Input Points ---\n",
      "Generated input points with shape: torch.Size([64, 256])\n",
      "\n",
      "--- Computing Initial Embeddings ---\n",
      "Initial embeddings shape: torch.Size([64, 256, 384])\n",
      "\n",
      "--- Processing Layer 0 ---\n",
      "  Getting activations for layer 0\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -3.1637, max: 4.2184, mean: 0.0014\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.2104, max: 0.3011, norm: 1.3428\n",
      "  Covariance stats - min: -0.0859, max: 0.1895\n",
      "  Covariance diagonal - min: 0.0654, max: 0.1895\n",
      "  No previous mask, creating diagonal mask\n",
      "  Created diagonal mask: 384x384, 384 True elements\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 1.3428\n",
      "  Masked covariance eigenvalues range: 0.065439 to 0.189489\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.3416, max: 2.3418, mean: 0.0013\n",
      "\n",
      "--- Processing Layer 1 ---\n",
      "  Getting activations for layer 1\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -2.1482, max: 2.4351, mean: -0.0006\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.5808, max: 0.7171, norm: 3.3233\n",
      "  Covariance stats - min: -0.0023, max: 0.1861\n",
      "  Covariance diagonal - min: 0.0654, max: 0.1861\n",
      "  No previous mask, creating diagonal mask\n",
      "  Created diagonal mask: 384x384, 384 True elements\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 3.3233\n",
      "  Masked covariance eigenvalues range: 0.065365 to 0.186147\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.3853, max: 2.7782, mean: -0.0007\n",
      "\n",
      "--- Processing Layer 2 ---\n",
      "  Getting activations for layer 2\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -2.5822, max: 2.4248, mean: -0.0027\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.7651, max: 0.8842, norm: 4.2790\n",
      "  Covariance stats - min: -0.0032, max: 0.1829\n",
      "  Covariance diagonal - min: 0.0675, max: 0.1829\n",
      "  No previous mask, creating diagonal mask\n",
      "  Created diagonal mask: 384x384, 384 True elements\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 4.2790\n",
      "  Masked covariance eigenvalues range: 0.067464 to 0.182906\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.6185, max: 2.7734, mean: -0.0029\n",
      "\n",
      "--- Processing Layer 3 ---\n",
      "  Getting activations for layer 3\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -2.3025, max: 2.4504, mean: -0.0015\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.7199, max: 0.9599, norm: 4.0979\n",
      "  Covariance stats - min: -0.0047, max: 0.1786\n",
      "  Covariance diagonal - min: 0.0709, max: 0.1786\n",
      "  No previous mask, creating diagonal mask\n",
      "  Created diagonal mask: 384x384, 384 True elements\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 4.0979\n",
      "  Masked covariance eigenvalues range: 0.070908 to 0.178649\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.5829, max: 2.8647, mean: -0.0015\n",
      "\n",
      "--- Processing Layer 4 ---\n",
      "  Getting activations for layer 4\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -2.1579, max: 2.2576, mean: 0.0002\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.6740, max: 0.7418, norm: 4.0794\n",
      "  Covariance stats - min: -0.0066, max: 0.1838\n",
      "  Covariance diagonal - min: 0.0777, max: 0.1838\n",
      "  No previous mask, creating diagonal mask\n",
      "  Created diagonal mask: 384x384, 384 True elements\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 4.0794\n",
      "  Masked covariance eigenvalues range: 0.077664 to 0.183793\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.4296, max: 2.6362, mean: 0.0003\n",
      "\n",
      "--- Processing Layer 5 ---\n",
      "  Getting activations for layer 5\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -2.0439, max: 2.1543, mean: 0.0076\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.4987, max: 0.5193, norm: 3.8268\n",
      "  Covariance stats - min: -0.0186, max: 0.1967\n",
      "  Covariance diagonal - min: 0.0915, max: 0.1967\n",
      "  No previous mask, creating diagonal mask\n",
      "  Created diagonal mask: 384x384, 384 True elements\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 3.8268\n",
      "  Masked covariance eigenvalues range: 0.091542 to 0.196692\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.3681, max: 2.5684, mean: 0.0076\n",
      "\n",
      "--- Processing Final Layer (Output) ---\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 65\n",
      "  Mean stats - min: -4.7427, max: 2.6231, norm: 19.2345\n",
      "  Covariance stats - min: -0.2662, max: 1.2203\n",
      "  Covariance diagonal - min: 0.5223, max: 1.2203\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 19.2345\n",
      "  Masked covariance eigenvalues range: 0.087513 to 9.730764\n",
      "\n",
      "--- Finding True Outputs ---\n",
      "  Input shape: torch.Size([64, 256])\n",
      "  Final logits shape: torch.Size([64, 256, 65])\n",
      "  Logits stats - min: -11.2180, max: 18.6496\n",
      "  Generated 3840 tokens: a top byNal naa\n",
      "nmm ...\n",
      "\n",
      "--- Computing Surprise of Estimate ---\n",
      "  First sample log prob: -95.2603\n",
      "  Sample stats - min: -5.6594, max: 3.7722\n",
      "  Total samples processed: 983040\n",
      "  Average log prob: -205.9925\n",
      "  Surprise (negative log likelihood): 205.9925\n",
      "\n",
      "--- Computing Argument Surprise Metric 1 ---\n",
      "  Layer 0: 384.0/147456 elements tracked, surprise: 0\n",
      "  Layer 1: 384.0/147456 elements tracked, surprise: 0\n",
      "  Layer 2: 384.0/147456 elements tracked, surprise: 0\n",
      "  Layer 3: 384.0/147456 elements tracked, surprise: 0\n",
      "  Layer 4: 384.0/147456 elements tracked, surprise: 0\n",
      "  Layer 5: 384.0/147456 elements tracked, surprise: 0\n",
      "  Total argument surprise: 0.0\n",
      "\n",
      "=============== STEP 1 SUMMARY ===============\n",
      "Surprise Estimate: 205.9925\n",
      "Argument Surprise: 0.0000\n",
      "Total Surprise: 205.9925\n",
      "Best So Far: 100000.0000\n",
      "Sample Generated Tokens: a top byNal naa\n",
      "nmm vtRImwr uugoIoEsse a itaw ne  \n",
      "🎉 NEW BEST SURPRISE: 205.9925\n",
      "\n",
      "==================== Training Step 2/1000 ====================\n",
      "\n",
      "--- Generating 60 Input Points ---\n",
      "Generated input points with shape: torch.Size([64, 256])\n",
      "\n",
      "--- Computing Initial Embeddings ---\n",
      "Initial embeddings shape: torch.Size([64, 256, 384])\n",
      "\n",
      "--- Processing Layer 0 ---\n",
      "  Getting activations for layer 0\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -3.3230, max: 4.2184, mean: 0.0013\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.2095, max: 0.3015, norm: 1.3426\n",
      "  Covariance stats - min: -0.0858, max: 0.1898\n",
      "  Covariance diagonal - min: 0.0654, max: 0.1898\n",
      "  Mask evolution: 384 -> 12490 True elements\n",
      "  Flip attempts: 7516, accepted: 6053\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 1.3426\n",
      "  Masked covariance eigenvalues range: 0.000010 to 0.286841\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.1493, max: 2.2345, mean: 0.0013\n",
      "\n",
      "--- Processing Layer 1 ---\n",
      "  Getting activations for layer 1\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -2.1434, max: 2.3001, mean: -0.0004\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.5874, max: 0.7278, norm: 3.3758\n",
      "  Covariance stats - min: -0.0560, max: 0.1847\n",
      "  Covariance diagonal - min: 0.0657, max: 0.1847\n",
      "  Mask evolution: 384 -> 15240 True elements\n",
      "  Flip attempts: 7462, accepted: 7428\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 3.3758\n",
      "  Masked covariance eigenvalues range: 0.051474 to 0.189404\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.5307, max: 2.6711, mean: -0.0007\n",
      "\n",
      "--- Processing Layer 2 ---\n",
      "  Getting activations for layer 2\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -2.2379, max: 2.7648, mean: -0.0033\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.7790, max: 0.8999, norm: 4.3457\n",
      "  Covariance stats - min: -0.0309, max: 0.1819\n",
      "  Covariance diagonal - min: 0.0678, max: 0.1819\n",
      "  Mask evolution: 384 -> 15288 True elements\n",
      "  Flip attempts: 7495, accepted: 7452\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 4.3457\n",
      "  Masked covariance eigenvalues range: 0.065500 to 0.186399\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.4748, max: 2.8638, mean: -0.0030\n",
      "\n",
      "--- Processing Layer 3 ---\n",
      "  Getting activations for layer 3\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -2.2617, max: 2.5053, mean: -0.0017\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.7385, max: 0.9701, norm: 4.1402\n",
      "  Covariance stats - min: -0.0229, max: 0.1787\n",
      "  Covariance diagonal - min: 0.0711, max: 0.1787\n",
      "  Mask evolution: 384 -> 15328 True elements\n",
      "  Flip attempts: 7503, accepted: 7472\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 4.1402\n",
      "  Masked covariance eigenvalues range: 0.070224 to 0.179955\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.4962, max: 2.8860, mean: -0.0016\n",
      "\n",
      "--- Processing Layer 4 ---\n",
      "  Getting activations for layer 4\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -2.2019, max: 2.3439, mean: 0.0003\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.6927, max: 0.7632, norm: 4.0978\n",
      "  Covariance stats - min: -0.0184, max: 0.1836\n",
      "  Covariance diagonal - min: 0.0775, max: 0.1836\n",
      "  Mask evolution: 384 -> 15194 True elements\n",
      "  Flip attempts: 7447, accepted: 7405\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 4.0978\n",
      "  Masked covariance eigenvalues range: 0.073608 to 0.185526\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.6255, max: 2.6056, mean: 0.0003\n",
      "\n",
      "--- Processing Layer 5 ---\n",
      "  Getting activations for layer 5\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -2.0206, max: 2.3827, mean: 0.0073\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.4849, max: 0.5102, norm: 3.7791\n",
      "  Covariance stats - min: -0.0189, max: 0.1961\n",
      "  Covariance diagonal - min: 0.0919, max: 0.1961\n",
      "  Mask evolution: 384 -> 15224 True elements\n",
      "  Flip attempts: 7455, accepted: 7420\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 3.7791\n",
      "  Masked covariance eigenvalues range: 0.068263 to 0.206535\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.3505, max: 2.7151, mean: 0.0073\n",
      "\n",
      "--- Processing Final Layer (Output) ---\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 65\n",
      "  Mean stats - min: -4.7489, max: 2.5634, norm: 19.0986\n",
      "  Covariance stats - min: -0.3202, max: 1.3137\n",
      "  Covariance diagonal - min: 0.5452, max: 1.3137\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 19.0986\n",
      "  Masked covariance eigenvalues range: 0.086248 to 10.705627\n",
      "\n",
      "--- Finding True Outputs ---\n",
      "  Input shape: torch.Size([64, 256])\n",
      "  Final logits shape: torch.Size([64, 256, 65])\n",
      "  Logits stats - min: -11.1422, max: 18.7941\n",
      "  Generated 3840 tokens: o  n\n",
      " ta sta ip  kan...\n",
      "\n",
      "--- Computing Surprise of Estimate ---\n",
      "  First sample log prob: -81.6142\n",
      "  Sample stats - min: -5.5034, max: 3.9359\n",
      "  Total samples processed: 983040\n",
      "  Average log prob: -185.1630\n",
      "  Surprise (negative log likelihood): 185.1630\n",
      "\n",
      "--- Computing Argument Surprise Metric 1 ---\n",
      "  Layer 0: 12490.0/147456 elements tracked, surprise: 12106.0\n",
      "  Layer 1: 15240.0/147456 elements tracked, surprise: 14856.0\n",
      "  Layer 2: 15288.0/147456 elements tracked, surprise: 14904.0\n",
      "  Layer 3: 15328.0/147456 elements tracked, surprise: 14944.0\n",
      "  Layer 4: 15194.0/147456 elements tracked, surprise: 14810.0\n",
      "  Layer 5: 15224.0/147456 elements tracked, surprise: 14840.0\n",
      "  Total argument surprise: 86460.0\n",
      "\n",
      "=============== STEP 2 SUMMARY ===============\n",
      "Surprise Estimate: 185.1630\n",
      "Argument Surprise: 86460.0000\n",
      "Total Surprise: 86645.1630\n",
      "Best So Far: 205.9925\n",
      "Sample Generated Tokens: o  n\n",
      " ta sta ip  kanh,at :: re\n",
      "reguanuo a  oiSoine\n",
      "\n",
      "==================== Training Step 3/1000 ====================\n",
      "\n",
      "--- Generating 60 Input Points ---\n",
      "Generated input points with shape: torch.Size([64, 256])\n",
      "\n",
      "--- Computing Initial Embeddings ---\n",
      "Initial embeddings shape: torch.Size([64, 256, 384])\n",
      "\n",
      "--- Processing Layer 0 ---\n",
      "  Getting activations for layer 0\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -3.1637, max: 4.2184, mean: 0.0013\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.2111, max: 0.3023, norm: 1.3434\n",
      "  Covariance stats - min: -0.0860, max: 0.1905\n",
      "  Covariance diagonal - min: 0.0653, max: 0.1905\n",
      "  Mask evolution: 384 -> 12378 True elements\n",
      "  Flip attempts: 7407, accepted: 5997\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 1.3434\n",
      "  Masked covariance eigenvalues range: 0.000017 to 0.292259\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.4072, max: 2.3146, mean: 0.0013\n",
      "\n",
      "--- Processing Layer 1 ---\n",
      "  Getting activations for layer 1\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -1.9768, max: 2.2743, mean: -0.0006\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.5888, max: 0.7256, norm: 3.3711\n",
      "  Covariance stats - min: -0.0815, max: 0.1863\n",
      "  Covariance diagonal - min: 0.0655, max: 0.1863\n",
      "  Mask evolution: 384 -> 15124 True elements\n",
      "  Flip attempts: 7414, accepted: 7370\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 3.3711\n",
      "  Masked covariance eigenvalues range: 0.049123 to 0.199563\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.4526, max: 2.6254, mean: -0.0007\n",
      "\n",
      "--- Processing Layer 2 ---\n",
      "  Getting activations for layer 2\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -2.1860, max: 2.6986, mean: -0.0029\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.7760, max: 0.8995, norm: 4.3389\n",
      "  Covariance stats - min: -0.0313, max: 0.1835\n",
      "  Covariance diagonal - min: 0.0678, max: 0.1835\n",
      "  Mask evolution: 384 -> 14990 True elements\n",
      "  Flip attempts: 7334, accepted: 7303\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 4.3389\n",
      "  Masked covariance eigenvalues range: 0.065804 to 0.184012\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.7732, max: 2.8648, mean: -0.0029\n",
      "\n",
      "--- Processing Layer 3 ---\n",
      "  Getting activations for layer 3\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -2.2553, max: 2.6428, mean: -0.0014\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.7355, max: 0.9678, norm: 4.1351\n",
      "  Covariance stats - min: -0.0185, max: 0.1781\n",
      "  Covariance diagonal - min: 0.0710, max: 0.1781\n",
      "  Mask evolution: 384 -> 14942 True elements\n",
      "  Flip attempts: 7308, accepted: 7279\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 4.1351\n",
      "  Masked covariance eigenvalues range: 0.070314 to 0.179084\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.5810, max: 2.8370, mean: -0.0014\n",
      "\n",
      "--- Processing Layer 4 ---\n",
      "  Getting activations for layer 4\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -2.1922, max: 2.4136, mean: 0.0007\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.6892, max: 0.7672, norm: 4.0829\n",
      "  Covariance stats - min: -0.0071, max: 0.1831\n",
      "  Covariance diagonal - min: 0.0773, max: 0.1831\n",
      "  Mask evolution: 384 -> 14992 True elements\n",
      "  Flip attempts: 7346, accepted: 7304\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 4.0829\n",
      "  Masked covariance eigenvalues range: 0.072318 to 0.184258\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.4096, max: 2.7476, mean: 0.0007\n",
      "\n",
      "--- Processing Layer 5 ---\n",
      "  Getting activations for layer 5\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -2.0103, max: 2.1741, mean: 0.0077\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.4882, max: 0.5097, norm: 3.7647\n",
      "  Covariance stats - min: -0.0185, max: 0.1950\n",
      "  Covariance diagonal - min: 0.0912, max: 0.1950\n",
      "  Mask evolution: 384 -> 15192 True elements\n",
      "  Flip attempts: 7451, accepted: 7404\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 3.7647\n",
      "  Masked covariance eigenvalues range: 0.065445 to 0.203891\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.3391, max: 2.5827, mean: 0.0076\n",
      "\n",
      "--- Processing Final Layer (Output) ---\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 65\n",
      "  Mean stats - min: -4.7442, max: 2.5641, norm: 18.9537\n",
      "  Covariance stats - min: -0.3294, max: 1.3076\n",
      "  Covariance diagonal - min: 0.5485, max: 1.3076\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 18.9537\n",
      "  Masked covariance eigenvalues range: 0.085867 to 10.744364\n",
      "\n",
      "--- Finding True Outputs ---\n",
      "  Input shape: torch.Size([64, 256])\n",
      "  Final logits shape: torch.Size([64, 256, 65])\n",
      "  Logits stats - min: -11.2044, max: 18.4639\n",
      "  Generated 3840 tokens:  lCtAheolaaio\n",
      "tnllIb...\n",
      "\n",
      "--- Computing Surprise of Estimate ---\n",
      "  First sample log prob: -95.8771\n",
      "  Sample stats - min: -6.3257, max: 3.1162\n",
      "  Total samples processed: 983040\n",
      "  Average log prob: -184.5800\n",
      "  Surprise (negative log likelihood): 184.5800\n",
      "\n",
      "--- Computing Argument Surprise Metric 1 ---\n",
      "  Layer 0: 12378.0/147456 elements tracked, surprise: 11994.0\n",
      "  Layer 1: 15124.0/147456 elements tracked, surprise: 14740.0\n",
      "  Layer 2: 14990.0/147456 elements tracked, surprise: 14606.0\n",
      "  Layer 3: 14942.0/147456 elements tracked, surprise: 14558.0\n",
      "  Layer 4: 14992.0/147456 elements tracked, surprise: 14608.0\n",
      "  Layer 5: 15192.0/147456 elements tracked, surprise: 14808.0\n",
      "  Total argument surprise: 85314.0\n",
      "\n",
      "=============== STEP 3 SUMMARY ===============\n",
      "Surprise Estimate: 184.5800\n",
      "Argument Surprise: 85314.0000\n",
      "Total Surprise: 85498.5800\n",
      "Best So Far: 205.9925\n",
      "Sample Generated Tokens:  lCtAheolaaio\n",
      "tnllIb A n'spw o  sv \n",
      "ey eysbeeIo  o\n",
      "\n",
      "==================== Training Step 4/1000 ====================\n",
      "\n",
      "--- Generating 60 Input Points ---\n",
      "Generated input points with shape: torch.Size([64, 256])\n",
      "\n",
      "--- Computing Initial Embeddings ---\n",
      "Initial embeddings shape: torch.Size([64, 256, 384])\n",
      "\n",
      "--- Processing Layer 0 ---\n",
      "  Getting activations for layer 0\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -3.0029, max: 4.2184, mean: 0.0014\n",
      "  Statistics calculation: 60 activations -> 983040 total samples\n",
      "  Feature dimension: 384\n",
      "  Mean stats - min: -0.2121, max: 0.3022, norm: 1.3433\n",
      "  Covariance stats - min: -0.0855, max: 0.1905\n",
      "  Covariance diagonal - min: 0.0650, max: 0.1905\n",
      "  Mask evolution: 384 -> 12846 True elements\n",
      "  Flip attempts: 7519, accepted: 6231\n",
      "  Successfully created Gaussian distribution\n",
      "  Mean norm: 1.3433\n",
      "  Masked covariance eigenvalues range: 0.000025 to 0.289323\n",
      "  Sampling 60 activations with shape (64, 256, 384)\n",
      "  Successfully sampled 983040 points\n",
      "  Sample stats - min: -2.3244, max: 2.5205, mean: 0.0013\n",
      "\n",
      "--- Processing Layer 1 ---\n",
      "  Getting activations for layer 1\n",
      "    Input shape: torch.Size([64, 256, 384]), output shape: torch.Size([64, 256, 384])\n",
      "    Output stats - min: -1.9977, max: 2.2221, mean: -0.0006\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 392\u001b[39m\n\u001b[32m    390\u001b[39m \u001b[38;5;66;03m# Process each layer\u001b[39;00m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_layer):\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m     empirical_mean, covariance_matrix, layer_activations = \u001b[43mpropagate_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_layer_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    393\u001b[39m     empirical_means.append(empirical_mean)\n\u001b[32m    394\u001b[39m     covariance_matrices.append(covariance_matrix)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 126\u001b[39m, in \u001b[36mpropagate_distribution\u001b[39m\u001b[34m(input_points, layer, model)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpropagate_distribution\u001b[39m(input_points, layer, model):\n\u001b[32m    125\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Processing Layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     layer_activations = \u001b[43mget_activation\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m     layer_empirical_mean, layer_covariance_matrix = calculate_layer_statistics(layer_activations)\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_empirical_mean, layer_covariance_matrix, layer_activations\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 107\u001b[39m, in \u001b[36mget_activation\u001b[39m\u001b[34m(input_points, layer, model, device)\u001b[39m\n\u001b[32m    105\u001b[39m ln1_out = block.ln1(x)\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Self-attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m sa_out = \u001b[43mblock\u001b[49m\u001b[43m.\u001b[49m\u001b[43msa\u001b[49m\u001b[43m(\u001b[49m\u001b[43mln1_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;66;03m# Residual connection after attention\u001b[39;00m\n\u001b[32m    109\u001b[39m x = x + sa_out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Messing_Around/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Messing_Around/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 100\u001b[39m, in \u001b[36mMultiHeadAttention.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     out = torch.cat(\u001b[43m[\u001b[49m\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheads\u001b[49m\u001b[43m]\u001b[49m, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    101\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.dropout(\u001b[38;5;28mself\u001b[39m.proj(out))\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 100\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     out = torch.cat([\u001b[43mh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.heads], dim=-\u001b[32m1\u001b[39m)\n\u001b[32m    101\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.dropout(\u001b[38;5;28mself\u001b[39m.proj(out))\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Messing_Around/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Messing_Around/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mHead.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     81\u001b[39m wei = q @ k.transpose(-\u001b[32m2\u001b[39m,-\u001b[32m1\u001b[39m) * k.shape[-\u001b[32m1\u001b[39m]**-\u001b[32m0.5\u001b[39m \u001b[38;5;66;03m# (B, T, hs) @ (B, hs, T) -> (B, T, T)\u001b[39;00m\n\u001b[32m     82\u001b[39m wei = wei.masked_fill(\u001b[38;5;28mself\u001b[39m.tril[:T, :T] == \u001b[32m0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m-inf\u001b[39m\u001b[33m'\u001b[39m)) \u001b[38;5;66;03m# (B, T, T)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m wei = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwei\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B, T, T)\u001b[39;00m\n\u001b[32m     84\u001b[39m wei = \u001b[38;5;28mself\u001b[39m.dropout(wei)\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# perform the weighted aggregation of the values\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Messing_Around/.venv/lib/python3.11/site-packages/torch/nn/functional.py:2140\u001b[39m, in \u001b[36msoftmax\u001b[39m\u001b[34m(input, dim, _stacklevel, dtype)\u001b[39m\n\u001b[32m   2138\u001b[39m     dim = _get_softmax_dim(\u001b[33m\"\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m.dim(), _stacklevel)\n\u001b[32m   2139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2140\u001b[39m     ret = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2141\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2142\u001b[39m     ret = \u001b[38;5;28minput\u001b[39m.softmax(dim, dtype=dtype)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "from torch.distributions import MultivariateNormal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "Enhanced version with comprehensive monitoring and visualization\n",
    "'''\n",
    "\n",
    "def calculate_layer_statistics(activations):\n",
    "    stacked_activations = []\n",
    "    for activation in activations:\n",
    "        # Ensure consistent dtype\n",
    "        activation = activation.float()\n",
    "        # Flatten batch and time dimensions: (B, T, n_embd) -> (B*T, n_embd)\n",
    "        flattened = activation.view(-1, activation.shape[-1])\n",
    "        stacked_activations.append(flattened)\n",
    "    all_samples = torch.cat(stacked_activations, dim=0)\n",
    "    \n",
    "    print(f\"  Statistics calculation: {len(activations)} activations -> {all_samples.shape[0]} total samples\")\n",
    "    print(f\"  Feature dimension: {all_samples.shape[-1]}\")\n",
    "    \n",
    "    # empirical mean μ̂ = (1/N) Σ(i=1 to N) x_i\n",
    "    empirical_mean = torch.mean(all_samples, dim=0)\n",
    "    # Center the data\n",
    "    centered_samples = all_samples - empirical_mean.unsqueeze(0)\n",
    "    # covariance matrix Σ̂ = (1/N) Σ(i=1 to N) (x_i - μ̂)(x_i - μ̂)^T\n",
    "    covariance_matrix = torch.mm(centered_samples.t(), centered_samples) / (all_samples.shape[0] - 1)\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"  Mean stats - min: {empirical_mean.min():.4f}, max: {empirical_mean.max():.4f}, norm: {empirical_mean.norm():.4f}\")\n",
    "    print(f\"  Covariance stats - min: {covariance_matrix.min():.4f}, max: {covariance_matrix.max():.4f}\")\n",
    "    print(f\"  Covariance diagonal - min: {torch.diag(covariance_matrix).min():.4f}, max: {torch.diag(covariance_matrix).max():.4f}\")\n",
    "    \n",
    "    return empirical_mean, covariance_matrix\n",
    "\n",
    "def create_sparse_argument_masks(covariance_matrix):\n",
    "    dim = covariance_matrix.shape[0]\n",
    "    # Create diagonal mask (to assume independence between activations)\n",
    "    mask = torch.eye(dim, dtype=torch.bool, device=covariance_matrix.device)\n",
    "    print(f\"  Created diagonal mask: {dim}x{dim}, {torch.sum(mask)} True elements\")\n",
    "    return mask\n",
    "\n",
    "def make_layer_mask(best_layer_mask, covariance_matrix, lr=0.05):\n",
    "    if best_layer_mask is None:\n",
    "        print(\"  No previous mask, creating diagonal mask\")\n",
    "        return create_sparse_argument_masks(covariance_matrix)\n",
    "    \n",
    "    new_mask = best_layer_mask.clone()\n",
    "    dim = best_layer_mask.shape[0]\n",
    "    original_true_count = torch.sum(new_mask).item()\n",
    "    \n",
    "    def is_positive_definite(matrix):\n",
    "        try:\n",
    "            torch.linalg.cholesky(matrix)\n",
    "            return True\n",
    "        except torch.linalg.LinAlgError:\n",
    "            return False\n",
    "    \n",
    "    # Go through upper triangular positions\n",
    "    positions = [(i, j) for i in range(dim) for j in range(i, dim)]\n",
    "    random.shuffle(positions)\n",
    "    flips_attempted = 0\n",
    "    flips_accepted = 0\n",
    "    \n",
    "    for i, j in positions:\n",
    "        # Skip with probability (1 - lr)\n",
    "        if random.random() >= lr:\n",
    "            continue\n",
    "        flips_attempted += 1\n",
    "        \n",
    "        # Try flipping the bit\n",
    "        original_val = new_mask[i, j].item()\n",
    "        new_mask[i, j] = not original_val\n",
    "        # Maintain symmetry\n",
    "        if i != j:\n",
    "            new_mask[j, i] = new_mask[i, j]\n",
    "        # Test if the masked matrix is still positive definite\n",
    "        masked_matrix = covariance_matrix * new_mask.float()\n",
    "        if not is_positive_definite(masked_matrix):\n",
    "            new_mask[i, j] = original_val\n",
    "            if i != j: \n",
    "                new_mask[j, i] = original_val\n",
    "        else:\n",
    "            flips_accepted += 1\n",
    "    \n",
    "    final_true_count = torch.sum(new_mask).item()\n",
    "    print(f\"  Mask evolution: {original_true_count} -> {final_true_count} True elements\")\n",
    "    print(f\"  Flip attempts: {flips_attempted}, accepted: {flips_accepted}\")\n",
    "    \n",
    "    return new_mask\n",
    "\n",
    "def get_activation(input_points, layer, model, device='cpu'):\n",
    "    print(f\"  Getting activations for layer {layer}\")\n",
    "    layer_activations = []\n",
    "    block_idx = layer\n",
    "    for i, sampled_activation in enumerate(input_points):\n",
    "        sampled_activation = sampled_activation.to(device).float()  # Ensure float type\n",
    "        with torch.no_grad():\n",
    "            x = sampled_activation\n",
    "            # Pass through the specific transformer block\n",
    "            block = model.blocks[block_idx]\n",
    "            # Pre-attention layer norm\n",
    "            ln1_out = block.ln1(x)\n",
    "            # Self-attention\n",
    "            sa_out = block.sa(ln1_out)\n",
    "            # Residual connection after attention\n",
    "            x = x + sa_out\n",
    "            # Pre-feedforward layer norm\n",
    "            ln2_out = block.ln2(x)\n",
    "            # Feedforward\n",
    "            ffwd_out = block.ffwd(ln2_out)\n",
    "            # Residual connection after feedforward\n",
    "            x = x + ffwd_out\n",
    "            layer_activations.append(x)\n",
    "            \n",
    "            if i == 0:  # Print stats for first activation\n",
    "                print(f\"    Input shape: {sampled_activation.shape}, output shape: {x.shape}\")\n",
    "                print(f\"    Output stats - min: {x.min():.4f}, max: {x.max():.4f}, mean: {x.mean():.4f}\")\n",
    "    \n",
    "    return layer_activations\n",
    "\n",
    "def propagate_distribution(input_points, layer, model):\n",
    "    print(f\"\\n--- Processing Layer {layer} ---\")\n",
    "    layer_activations = get_activation(input_points, layer, model)\n",
    "    layer_empirical_mean, layer_covariance_matrix = calculate_layer_statistics(layer_activations)\n",
    "    return layer_empirical_mean, layer_covariance_matrix, layer_activations\n",
    "\n",
    "def create_gaussian_distribution(empirical_mean, covariance_matrix, layer_mask):\n",
    "    # Only keep covariance terms where mask is True, set others to 0\n",
    "    masked_cov = covariance_matrix * layer_mask.float()\n",
    "    \n",
    "    # Check if the masked covariance is positive definite\n",
    "    try:\n",
    "        distribution = MultivariateNormal(loc=empirical_mean, covariance_matrix=masked_cov)\n",
    "        print(f\"  Successfully created Gaussian distribution\")\n",
    "        print(f\"  Mean norm: {empirical_mean.norm():.4f}\")\n",
    "        print(f\"  Masked covariance eigenvalues range: {torch.linalg.eigvals(masked_cov).real.min():.6f} to {torch.linalg.eigvals(masked_cov).real.max():.6f}\")\n",
    "        return distribution\n",
    "    except Exception as e:\n",
    "        print(f\"  Error creating Gaussian: {e}\")\n",
    "        # Fallback to diagonal covariance\n",
    "        diag_cov = torch.diag(torch.diag(masked_cov))\n",
    "        distribution = MultivariateNormal(loc=empirical_mean, covariance_matrix=diag_cov)\n",
    "        print(f\"  Fallback to diagonal covariance\")\n",
    "        return distribution\n",
    "\n",
    "def sample_next_layer_inputs(estimated_layer_gaussian, original_activations, num_activations):\n",
    "    # Get the original shape from one of the activations\n",
    "    sample_activation = original_activations[0]\n",
    "    batch_size, seq_len, feature_dim = sample_activation.shape\n",
    "    \n",
    "    print(f\"  Sampling {num_activations} activations with shape ({batch_size}, {seq_len}, {feature_dim})\")\n",
    "    \n",
    "    # Sample from the distribution\n",
    "    # We need (num_activations * batch_size * seq_len) samples\n",
    "    total_samples_needed = num_activations * batch_size * seq_len\n",
    "    try:\n",
    "        sampled_flat = estimated_layer_gaussian.sample((total_samples_needed,))\n",
    "        print(f\"  Successfully sampled {total_samples_needed} points\")\n",
    "        print(f\"  Sample stats - min: {sampled_flat.min():.4f}, max: {sampled_flat.max():.4f}, mean: {sampled_flat.mean():.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Sampling error: {e}\")\n",
    "        # Fallback to mean values\n",
    "        sampled_flat = estimated_layer_gaussian.mean.unsqueeze(0).repeat(total_samples_needed, 1)\n",
    "        print(f\"  Fallback to mean values\")\n",
    "    \n",
    "    # Reshape to match the expected format: (num_activations, batch_size, seq_len, feature_dim)\n",
    "    sampled_activations = sampled_flat.view(num_activations, batch_size, seq_len, feature_dim)\n",
    "    \n",
    "    # Convert back to list format expected by the rest of the code\n",
    "    current_layer_inputs = [sampled_activations[i] for i in range(num_activations)]\n",
    "    \n",
    "    return current_layer_inputs\n",
    "\n",
    "def find_true_outputs(model, input_points, device='cpu'):\n",
    "    print(\"\\n--- Finding True Outputs ---\")\n",
    "    true_outputs = []\n",
    "    generated_tokens = []  # Store the actual tokens generated\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, input_point in enumerate(input_points):\n",
    "            input_point = input_point.to(device).long()  # Ensure long type for embeddings\n",
    "            B, T = input_point.shape\n",
    "            \n",
    "            # Token embeddings\n",
    "            tok_emb = model.token_embedding_table(input_point).float()  # (B, T, n_embd)\n",
    "            \n",
    "            # Position embeddings\n",
    "            pos_emb = model.position_embedding_table(torch.arange(T, device=device)).float()  # (T, n_embd)\n",
    "            \n",
    "            # Combined embeddings\n",
    "            x = tok_emb + pos_emb  # (B, T, n_embd)\n",
    "            \n",
    "            # Pass through all transformer blocks\n",
    "            for block in model.blocks:\n",
    "                # Pre-attention layer norm\n",
    "                ln1_out = block.ln1(x)\n",
    "                # Self-attention\n",
    "                sa_out = block.sa(ln1_out)\n",
    "                # Residual connection after attention\n",
    "                x = x + sa_out\n",
    "                # Pre-feedforward layer norm\n",
    "                ln2_out = block.ln2(x)\n",
    "                # Feedforward\n",
    "                ffwd_out = block.ffwd(ln2_out)\n",
    "                # Residual connection after feedforward\n",
    "                x = x + ffwd_out\n",
    "            \n",
    "            # Final layer norm\n",
    "            ln_f_out = model.ln_f(x)  # (B, T, n_embd)\n",
    "            \n",
    "            # Language model head (logits)\n",
    "            logits = model.lm_head(ln_f_out)  # (B, T, vocab_size)\n",
    "            \n",
    "            if i == 0:  # Print stats for first input\n",
    "                print(f\"  Input shape: {input_point.shape}\")\n",
    "                print(f\"  Final logits shape: {logits.shape}\")\n",
    "                print(f\"  Logits stats - min: {logits.min():.4f}, max: {logits.max():.4f}\")\n",
    "            \n",
    "            # Convert logits to actual tokens\n",
    "            # Take the last token prediction for each sequence\n",
    "            last_token_logits = logits[:, -1, :]  # (B, vocab_size)\n",
    "            predicted_token_ids = torch.argmax(last_token_logits, dim=-1)  # (B,)\n",
    "            \n",
    "            # Decode to actual text\n",
    "            for batch_idx in range(B):\n",
    "                token_id = predicted_token_ids[batch_idx].item()\n",
    "                predicted_char = itos[token_id]  # Convert to character using your decoder\n",
    "                generated_tokens.append(predicted_char)\n",
    "            \n",
    "            # Flatten the logits to match expected input format for calculate_layer_statistics\n",
    "            # This converts (B, T, vocab_size) -> (B*T, vocab_size)\n",
    "            flattened_logits = logits.view(-1, logits.shape[-1])\n",
    "            true_outputs.append(flattened_logits)\n",
    "    \n",
    "    print(f\"  Generated {len(generated_tokens)} tokens: {''.join(generated_tokens[:20])}...\")\n",
    "    return true_outputs, generated_tokens\n",
    "\n",
    "def surprise_of_estimate(true_samples, estimated_output_distribution):\n",
    "    print(\"\\n--- Computing Surprise of Estimate ---\")\n",
    "    total_log_prob = 0.0\n",
    "    sample_count = 0\n",
    "    \n",
    "    for i, sample in enumerate(true_samples):\n",
    "        # Process each sample individually\n",
    "        for j in range(sample.shape[0]):\n",
    "            single_sample = sample[j]  # Single vector of vocab_size\n",
    "            try:\n",
    "                log_prob = estimated_output_distribution.log_prob(single_sample)\n",
    "                total_log_prob += log_prob\n",
    "                sample_count += 1\n",
    "                \n",
    "                if i == 0 and j == 0:  # Print stats for first sample\n",
    "                    print(f\"  First sample log prob: {log_prob:.4f}\")\n",
    "                    print(f\"  Sample stats - min: {single_sample.min():.4f}, max: {single_sample.max():.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error computing log prob for sample {i},{j}: {e}\")\n",
    "                # Use a large negative log prob as penalty\n",
    "                total_log_prob += -1000.0\n",
    "                sample_count += 1\n",
    "    \n",
    "    surprise = -(total_log_prob / sample_count).item()\n",
    "    print(f\"  Total samples processed: {sample_count}\")\n",
    "    print(f\"  Average log prob: {total_log_prob / sample_count:.4f}\")\n",
    "    print(f\"  Surprise (negative log likelihood): {surprise:.4f}\")\n",
    "    return surprise\n",
    "\n",
    "def surprise_of_argument_metric1(layer_masks, covariance_matrices):\n",
    "    print(\"\\n--- Computing Argument Surprise Metric 1 ---\")\n",
    "    total_surprise = 0.0\n",
    "    for i, (mask, cov_matrix) in enumerate(zip(layer_masks, covariance_matrices)):\n",
    "        # Count number of True elements in the mask (|πᵢ|)\n",
    "        num_tracked_elements = torch.sum(mask.float()).item()\n",
    "        # Dimension of the space (dim(Xᵢ))\n",
    "        dimension = cov_matrix.shape[0]\n",
    "        # Surprise is the excess over diagonal elements\n",
    "        layer_surprise = num_tracked_elements - dimension\n",
    "        layer_surprise = max(0, layer_surprise)\n",
    "        total_surprise += layer_surprise\n",
    "        print(f\"  Layer {i}: {num_tracked_elements}/{dimension**2} elements tracked, surprise: {layer_surprise}\")\n",
    "    \n",
    "    print(f\"  Total argument surprise: {total_surprise}\")\n",
    "    return total_surprise\n",
    "\n",
    "def create_visualization_plots(step, surprise_estimates, surprise_metrics, total_surprises, best_surprises):\n",
    "    \"\"\"Create plots to visualize the training progress\"\"\"\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    steps = range(1, len(surprise_estimates) + 1)\n",
    "    \n",
    "    # Plot surprise estimates\n",
    "    ax1.plot(steps, surprise_estimates, 'b-', label='Surprise Estimate')\n",
    "    ax1.set_title('Surprise of Estimate Over Time')\n",
    "    ax1.set_xlabel('Training Step')\n",
    "    ax1.set_ylabel('Surprise')\n",
    "    ax1.grid(True)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot surprise metrics\n",
    "    ax2.plot(steps, surprise_metrics, 'r-', label='Argument Surprise')\n",
    "    ax2.set_title('Surprise of Argument Over Time')\n",
    "    ax2.set_xlabel('Training Step')\n",
    "    ax2.set_ylabel('Surprise')\n",
    "    ax2.grid(True)\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Plot total surprises\n",
    "    ax3.plot(steps, total_surprises, 'g-', label='Total Surprise')\n",
    "    ax3.plot(steps, best_surprises, 'g--', label='Best So Far')\n",
    "    ax3.set_title('Total Surprise Over Time')\n",
    "    ax3.set_xlabel('Training Step')\n",
    "    ax3.set_ylabel('Total Surprise')\n",
    "    ax3.grid(True)\n",
    "    ax3.legend()\n",
    "    \n",
    "    # Plot ratio\n",
    "    ratios = [est/met if met > 0 else 0 for est, met in zip(surprise_estimates, surprise_metrics)]\n",
    "    ax4.plot(steps, ratios, 'm-', label='Estimate/Argument Ratio')\n",
    "    ax4.set_title('Surprise Ratio Over Time')\n",
    "    ax4.set_xlabel('Training Step')\n",
    "    ax4.set_ylabel('Ratio')\n",
    "    ax4.grid(True)\n",
    "    ax4.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'training_progress_step_{step}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Load your model and other necessary components\n",
    "# (assuming these are defined from your first file)\n",
    "# model = GPTLanguageModel()\n",
    "# model.load_state_dict(torch.load('model.pth', map_location='cpu'))\n",
    "# device = 'cpu'\n",
    "# model = model.to(device)\n",
    "# model.eval()\n",
    "\n",
    "# Training tracking variables\n",
    "surprise_estimates_history = []\n",
    "surprise_metrics_history = []\n",
    "total_surprises_history = []\n",
    "best_surprises_history = []\n",
    "\n",
    "# Main training loop with enhanced monitoring\n",
    "print(\"=\" * 60)\n",
    "print(\"STARTING ENHANCED TRAINING WITH MONITORING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "num_activations = 600\n",
    "best_masks = [None] * 8  # Increased to 8 to match n_layer + 1\n",
    "min_surprise = 100000\n",
    "num_train_steps = 1000\n",
    "num_layers = 8\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(num_train_steps):\n",
    "        print(f\"\\n{'='*20} Training Step {i+1}/{num_train_steps} {'='*20}\")\n",
    "        \n",
    "        covariance_matrices = []\n",
    "        empirical_means = []\n",
    "        estimated_gaussians = []\n",
    "        layer_masks = []\n",
    "        input_points = []\n",
    "        \n",
    "        # Generate input points\n",
    "        print(f\"\\n--- Generating {num_activations} Input Points ---\")\n",
    "        for iter in range(num_activations):\n",
    "            xb, yb = get_batch('train')\n",
    "            input_point = xb.to(device)\n",
    "            input_points.append(input_point)\n",
    "        print(f\"Generated input points with shape: {input_points[0].shape}\")\n",
    "        \n",
    "        # Initialize current layer inputs (embeddings)\n",
    "        print(\"\\n--- Computing Initial Embeddings ---\")\n",
    "        current_layer_inputs = []\n",
    "        for input_point in input_points:\n",
    "            input_point = input_point.to(device).long()  # Ensure input is long type for embeddings\n",
    "            with torch.no_grad():\n",
    "                B, T = input_point.shape\n",
    "                # Token embeddings\n",
    "                tok_emb = model.token_embedding_table(input_point).float()  # (B, T, n_embd)\n",
    "                # Position embeddings\n",
    "                pos_emb = model.position_embedding_table(torch.arange(T, device=device)).float()  # (T, n_embd)\n",
    "                # Combined embeddings\n",
    "                x = tok_emb + pos_emb  # (B, T, n_embd)\n",
    "                current_layer_inputs.append(x)\n",
    "        print(f\"Initial embeddings shape: {current_layer_inputs[0].shape}\")\n",
    "        \n",
    "        # Process each layer\n",
    "        for layer in range(n_layer):\n",
    "            empirical_mean, covariance_matrix, layer_activations = propagate_distribution(current_layer_inputs, layer, model)\n",
    "            empirical_means.append(empirical_mean)\n",
    "            covariance_matrices.append(covariance_matrix)\n",
    "\n",
    "            layer_mask = make_layer_mask(best_masks[layer], covariance_matrix, lr=0.1)\n",
    "            layer_masks.append(layer_mask)\n",
    "            \n",
    "            estimated_layer_gaussian = create_gaussian_distribution(empirical_mean, covariance_matrix, layer_mask)\n",
    "            estimated_gaussians.append(estimated_layer_gaussian)\n",
    "            current_layer_inputs = sample_next_layer_inputs(\n",
    "                estimated_layer_gaussian, layer_activations, num_activations\n",
    "            )\n",
    "\n",
    "        # Final layer processing\n",
    "        print(\"\\n--- Processing Final Layer (Output) ---\")\n",
    "        layer_activations = []\n",
    "        for sampled_activation in current_layer_inputs:\n",
    "            sampled_activation = sampled_activation.to(device).float()  # Ensure float type\n",
    "            with torch.no_grad():\n",
    "                # Final layer norm\n",
    "                ln_f_out = model.ln_f(sampled_activation)\n",
    "                # Language model head (logits)\n",
    "                logits = model.lm_head(ln_f_out)\n",
    "                layer_activations.append(logits)\n",
    "        \n",
    "        empirical_mean, covariance_matrix = calculate_layer_statistics(layer_activations)\n",
    "        dim = covariance_matrix.shape[0]\n",
    "        layer_mask = torch.ones(dim, dim, dtype=torch.bool, device=covariance_matrix.device)\n",
    "        estimated_layer_gaussian = create_gaussian_distribution(empirical_mean, covariance_matrix, layer_mask)\n",
    "\n",
    "        estimated_output_distribution = estimated_layer_gaussian\n",
    "        true_outputs, generated_tokens = find_true_outputs(model, input_points, device)\n",
    "        \n",
    "        # Calculate surprises\n",
    "        surprise_estimate = surprise_of_estimate(true_outputs, estimated_output_distribution)\n",
    "        surprise_metric1 = surprise_of_argument_metric1(layer_masks, covariance_matrices)\n",
    "        total_surprise = surprise_estimate + surprise_metric1\n",
    "        \n",
    "        # Update tracking\n",
    "        surprise_estimates_history.append(surprise_estimate)\n",
    "        surprise_metrics_history.append(surprise_metric1)\n",
    "        total_surprises_history.append(total_surprise)\n",
    "        best_surprises_history.append(min_surprise)\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\n{'='*15} STEP {i+1} SUMMARY {'='*15}\")\n",
    "        print(f\"Surprise Estimate: {surprise_estimate:.4f}\")\n",
    "        print(f\"Argument Surprise: {surprise_metric1:.4f}\")\n",
    "        print(f\"Total Surprise: {total_surprise:.4f}\")\n",
    "        print(f\"Best So Far: {min_surprise:.4f}\")\n",
    "        print(f\"Sample Generated Tokens: {''.join(generated_tokens[:50])}\")\n",
    "        \n",
    "        # Update best masks if needed\n",
    "        if total_surprise < min_surprise:\n",
    "            min_surprise = total_surprise\n",
    "            best_masks = layer_masks.copy()\n",
    "            print(f\"🎉 NEW BEST SURPRISE: {min_surprise:.4f}\")\n",
    "        \n",
    "        # Create visualization every 10 steps\n",
    "        if (i + 1) % 10 == 0:\n",
    "            create_visualization_plots(i + 1, surprise_estimates_history, \n",
    "                                     surprise_metrics_history, total_surprises_history, \n",
    "                                     best_surprises_history)\n",
    "            print(f\"Saved visualization plot: training_progress_step_{i+1}.png\")\n",
    "\n",
    "print(f\"\\n{'='*20} TRAINING COMPLETE {'='*20}\")\n",
    "print(f\"Final best surprise: {min_surprise:.4f}\")\n",
    "print(f\"Final surprise estimate: {surprise_estimates_history[-1]:.4f}\")\n",
    "print(f\"Final argument surprise: {surprise_metrics_history[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82953f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
